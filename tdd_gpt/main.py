from agent import TddGPTAgent
from cli import CLITool
from langchain.chat_models import ChatOpenAI
from langchain.tools.file_management.write import WriteFileTool
from langchain.tools.file_management.read import ReadFileTool
from langchain.vectorstores import FAISS
from langchain.docstore import InMemoryDocstore
from langchain.embeddings import OpenAIEmbeddings
from langchain.memory.chat_message_histories import FileChatMessageHistory
import faiss
import argparse
import os
import base64
from openai import OpenAI
import re

def parse_args():
    # Create an argument parser
    parser = argparse.ArgumentParser(description='Generate code based on user stories')
    parser.add_argument('--model', type=str, default='gpt-4', help='Model parameter for the agent')
    parser.add_argument('--prompt', type=str, default="", help='User stories for the app or file path')
    parser.add_argument('--debug', action='store_true', help='Enable debug mode')
    parser.add_argument('--chat_history_file', type=str, help='Path to chat history file')
    parser.add_argument('--output_dir', type=str, default=os.getcwd(), help='Output directory for the files generated by the agent')
    parser.add_argument('--temperature', type=float, default=0.2, help='Temperature parameter for the model')
    parser.add_argument('--context_window', type=int, default=4096, help='Context window size for the agent')
    parser.add_argument('--image_file', type=str, default='', help='An image of the desired UI')
    
    # Parse the arguments
    return parser.parse_args()

def main():
    # Parse the arguments
    args = parse_args()

    chat_history_memory = None
    if args.chat_history_file:
        chat_history_memory = FileChatMessageHistory(args.chat_history_file)

    if not os.path.exists(args.output_dir):
      os.makedirs(args.output_dir)

    tools = [
        CLITool(),
        WriteFileTool(),
        ReadFileTool(),
    ]

    # Define your embedding model
    embeddings_model = OpenAIEmbeddings()

    # Initialize the vectorstore as empty
    embedding_size = 1536
    index = faiss.IndexFlatL2(embedding_size)
    vectorstore = FAISS(embeddings_model, index, InMemoryDocstore({}), {})

    # Initialize the agent
    agent = TddGPTAgent.from_llm_and_tools(
        output_dir=args.output_dir,
        tools=tools,
        llm=ChatOpenAI(model=args.model, temperature=args.temperature),
        memory=vectorstore.as_retriever(),
        chat_history_memory=chat_history_memory,
        context_window=args.context_window,
    )

    # Set verbose to be true if debug argument is passed
    agent.chain.verbose = args.debug

    prompt = args.prompt
    if os.path.isfile(prompt):
        with open(prompt, 'r') as file:
            prompt = file.read()

    if args.image_file:
        with open(args.image_file, 'rb') as file:
            encoded_string = base64.b64encode(file.read())

        client = OpenAI()

        if len(prompt.strip()) == 0:
            response = client.chat.completions.create(
                model="gpt-4-vision-preview",
                messages=[
                    {"role": "system", "content": "You are a meticulous Product Owner."},
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": "Analyze the screenshot and directly convert it to user stories which can be used to build the app in ReactJS. Focus solely on generating user stories that describe the features and functionalities shown in the wireframe. Please do not include any additional comments, descriptions of the wireframe, or analysis beyond the user stories themselves. Each user story should be concise and focus on user actions, needs, and outcomes as depicted in the screenshot. Start with 'Build a [app name] in ReactJS with the following features: '"},
                            {"type": "image", "image": encoded_string.decode("utf-8")},
                        ],
                    }
                ],
                max_tokens=4096,
            )

            prompt = response.choices[0].message.content + "\n"
            
        response = client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages=[
                {"role": "system", "content": "You are a creative frontend developer."},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": "Analyze the image and write the html and css code to clone the UI as closely as possible. Include the layout, UI components, page elements, buttons, forms, inputs, color scheme, typography, spacing, etc. Only output the code."},
                        {"type": "image", "image": encoded_string.decode("utf-8")},
                    ],
                }
            ],
            max_tokens=4096,
        )

        content = response.choices[0].message.content

        html = ""
        code_blocks = re.findall(r"```(.*?)```", content, re.DOTALL)
        for block in code_blocks:
            html += f"```{block.strip()}\n```\n"

        prompt += "\nThe UI should be similar to the following:\n" + html

    print(f'\033[92mPrompt:\033[0m\n{prompt}\n')

    agent.run([prompt])

if __name__ == "__main__":
    main()
